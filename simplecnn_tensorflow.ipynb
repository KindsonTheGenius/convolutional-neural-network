{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1seaFEuDtnPauo9bGTEYFBCUcJOqL8ysz","timestamp":1746455223475}],"collapsed_sections":["aDmLWgouYCKq"],"authorship_tag":"ABX9TyNAlgaJt5+MknJWOTmoTEhe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## CNN Using nn.Sequential"],"metadata":{"id":"aDmLWgouYCKq"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"3bsoBOuDX2U5"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","# Create a sequential layer\n","model1 = nn.Sequential(\n","\n","    # First convolutional layer\n","    nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1),\n","    nn.ReLU(),\n","    nn.MaxPool2d(kernel_size=2, stride=2),\n","\n","    # Second convolutional layer\n","    nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n","    nn.ReLU(),\n","    nn.MaxPool2d(kernel_size=2, stride=2),\n","\n","    nn.Flatten(),\n","\n","    nn.Linear(32 * 7 * 7, 10)\n",")"]},{"cell_type":"code","source":["# Testing the model\n","x1 = torch.randn(64, 1, 28, 28)\n","output1 = model1(x1)\n","print(output1.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1X7y3gPRcuD2","executionInfo":{"status":"ok","timestamp":1745959829844,"user_tz":-120,"elapsed":77,"user":{"displayName":"Kindson The Genius","userId":"02831998918358153324"}},"outputId":"b73cc62b-f8b4-4f4f-83fd-a10dfde0ea8b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([64, 10])\n"]}]},{"cell_type":"markdown","source":["## Equivalent CNN Using nn.Module"],"metadata":{"id":"1iGIqPz0a7XZ"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class SimpleCNN(nn.Module):\n","    def __init__(self):\n","        super(SimpleCNN, self).__init__()\n","\n","        # First convolutional block\n","        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n","        self.relu1 = nn.ReLU()\n","        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        # Second convolutional block\n","        self.conv2 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=1)\n","        self.relu2 = nn.ReLU()\n","        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        # Fully connected layers\n","        self.flatten = nn.Flatten()\n","        self.fc = nn.Linear(16 * 8 * 8, 10)\n","\n","    def forward(self, x):\n","        # Apply the first convolutional block\n","        x = self.conv1(x)\n","        x = self.relu1(x)\n","        x = self.pool1(x)\n","\n","        # Apply the second convolutional block\n","        x = self.conv2(x)\n","        x = self.relu2(x)\n","        x = self.pool2(x)\n","\n","        x = self.flatten(x)\n","        x = self.fc(x)\n","        return x"],"metadata":{"id":"myOpVuNPbAIE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train this model on the CIFAR10 dataset\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","#Hyperparameters\n","num_epochs = 10\n","batch_size = 64\n","learning_rate = 0.001\n","\n","# Data preprocessing\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"],"metadata":{"id":"WgifJgS2c6bf","executionInfo":{"status":"ok","timestamp":1746023878314,"user_tz":-120,"elapsed":25749,"user":{"displayName":"Kindson The Genius","userId":"02831998918358153324"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e2230820-60a0-43f2-9475-ac076bc9edb0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170M/170M [00:11<00:00, 14.5MB/s]\n"]}]},{"cell_type":"code","source":["# Instantiate and train the model\n","model2 = SimpleCNN().to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model2.parameters(), lr=learning_rate)\n","\n","#Train the model\n","total_step = len(train_loader)\n","for epoch in range(num_epochs):\n","    model2.train()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    for i, (images, labels) in enumerate(train_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        # Forward pass\n","        outputs = model2(images) # calculate the output\n","        loss = criterion(outputs, labels) # calculate the loss\n","\n","        # Backward pass and optimization\n","        optimizer.zero_grad() # reset the gradients\n","        loss.backward() # initiates the backpropagation process\n","        optimizer.step() # update model parameters\n","\n","        running_loss += loss.item() #update the loss\n","        _, predicted = torch.max(outputs.data, 1) # retrieve the index of max\n","        total += labels.size(0) # update the total\n","        correct += (predicted == labels).sum().item() # update the correct\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/total_step:.4f}, Accuracy: {100*correct/total:.2f}%')\n","\n","# Test the model\n","model2.eval() # Sets the model in evaluation mode\n","with torch.no_grad(): # disable gradient calculation\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.to(device) # move data to device\n","        labels = labels.to(device) # move data to device\n","        outputs = model2(images) # forward pass\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0) # update the total\n","        correct += (predicted == labels).sum().item() # update the correct\n","\n","    print(f'Test Accuracy: {100 * correct / total:.2f}%') # print the results\n","\n","# Save the model\n","torch.save(model2.state_dict(), 'simple_cnn.pth')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B3yghtAB6afc","executionInfo":{"status":"ok","timestamp":1746024237598,"user_tz":-120,"elapsed":353985,"user":{"displayName":"Kindson The Genius","userId":"02831998918358153324"}},"outputId":"67a27461-4760-4096-83d4-c8e80be930ee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Loss: 1.5301, Accuracy: 45.61%\n","Epoch [2/10], Loss: 1.2320, Accuracy: 56.56%\n","Epoch [3/10], Loss: 1.1135, Accuracy: 61.11%\n","Epoch [4/10], Loss: 1.0425, Accuracy: 63.74%\n","Epoch [5/10], Loss: 0.9958, Accuracy: 65.31%\n","Epoch [6/10], Loss: 0.9615, Accuracy: 66.37%\n","Epoch [7/10], Loss: 0.9340, Accuracy: 67.41%\n","Epoch [8/10], Loss: 0.9153, Accuracy: 68.13%\n","Epoch [9/10], Loss: 0.8985, Accuracy: 68.78%\n","Epoch [10/10], Loss: 0.8836, Accuracy: 69.25%\n","Test Accuracy: 66.44%\n"]}]},{"cell_type":"code","source":["#pip install tensorboard"],"metadata":{"id":"SKSsFG_9Q46r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualize in Tensorboard\n","import torch\n","import torchvision\n","from torch.utils.tensorboard import SummaryWriter\n","\n","# Writer will output to ./runs/ directory by default\n","writer = SummaryWriter(\"run/simple_cnn\")\n","dummy_input = torch.randn(64, 3, 32, 32) # mini-batch of 10 images\n","writer.add_graph(model2, dummy_input)\n","writer.close()\n"],"metadata":{"id":"eG2i8xAUQHq6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%load_ext tensorboard\n","%tensorboard --logdir run/simple_cnn"],"metadata":{"id":"vV8y3tGiR2uf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install pyngrok"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IURdY7f9KPHw","executionInfo":{"status":"ok","timestamp":1746024369871,"user_tz":-120,"elapsed":3431,"user":{"displayName":"Kindson The Genius","userId":"02831998918358153324"}},"outputId":"b8e83cb1-95d4-41e7-fa55-a6e595d39e4c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyngrok\n","  Downloading pyngrok-7.2.5-py3-none-any.whl.metadata (8.9 kB)\n","Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n","Downloading pyngrok-7.2.5-py3-none-any.whl (23 kB)\n","Installing collected packages: pyngrok\n","Successfully installed pyngrok-7.2.5\n"]}]},{"cell_type":"code","source":["# Google Colab runs in a cloud VM, so localhost:6006 is inaccessible. Instead, use ngrok to tunnel.\n","from pyngrok import ngrok"],"metadata":{"id":"MDuYsV9-KNEB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["LOG_DIR = \"run/simple_cnn\"\n","\n","# Kill previous TB instances\n","!pkill tensorboard\n","\n","# Start TensorBoard\n","get_ipython().system_raw(\n","    f'tensorboard --logdir {LOG_DIR} --host 0.0.0.0 --port 6006 &'\n",")\n","\n","from google.colab import userdata\n","auth_token = userdata.get('AUTH_TOKEN')\n","\n","# Open ngrok tunnel to TensorBoard\n","!ngrok authtoken {auth_token}\n","tb_url = ngrok.connect(6006)\n","print(f\"ðŸ”— TensorBoard is live at: {tb_url}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qXK63YrSKwj7","executionInfo":{"status":"ok","timestamp":1746024815171,"user_tz":-120,"elapsed":2210,"user":{"displayName":"Kindson The Genius","userId":"02831998918358153324"}},"outputId":"b8166dd3-f887-4599-fac5-7bb967369c11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n","ðŸ”— TensorBoard is live at: NgrokTunnel: \"https://88e4-35-229-230-199.ngrok-free.app\" -> \"http://localhost:6006\"\n"]}]}]}